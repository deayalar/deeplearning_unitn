{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DL Project wandb embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit ('dl_unitn': conda)",
      "name": "python371064bitdlunitncondad5dd323ef49745509346e8124c4613ec"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10-final"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9344fdf74e6048389de94ef7e24097a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b665af91f02147fe8d2d799cf485b25f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a7b49c77eaed45d7a6e69fae7b7ff184",
              "IPY_MODEL_75feda6df9ce4c02bc48faa34d890dbd"
            ]
          }
        },
        "b665af91f02147fe8d2d799cf485b25f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7b49c77eaed45d7a6e69fae7b7ff184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_167cbc5246da470d81aea6a0429197a0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 302,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 302,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d22b867029bd415785c9878b4287a90b"
          }
        },
        "75feda6df9ce4c02bc48faa34d890dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d175e701167d4205b0b84a391f17ed9b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 302/302 [00:27&lt;00:00, 10.89it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eead41d247e34cda8a7735905bd8e445"
          }
        },
        "167cbc5246da470d81aea6a0429197a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d22b867029bd415785c9878b4287a90b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d175e701167d4205b0b84a391f17ed9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eead41d247e34cda8a7735905bd8e445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc54899c2d384fec8a8443dcbe171a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bb283e0e26cc4f0ba2b5eb98a9a4dd9e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f95520d91d949898da438a850ff0053",
              "IPY_MODEL_06296f0d3eef4c8aa82bf3fcfcb3c7d9"
            ]
          }
        },
        "bb283e0e26cc4f0ba2b5eb98a9a4dd9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f95520d91d949898da438a850ff0053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_50c2d3a4fc2f4247a576149532264599",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f1994c81ccf4f1085477026ccbbab1b"
          }
        },
        "06296f0d3eef4c8aa82bf3fcfcb3c7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac353ca5c1a54301b5ab530a48a7251a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16196ee874fe4a69ae027fdce5ad6bde"
          }
        },
        "50c2d3a4fc2f4247a576149532264599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f1994c81ccf4f1085477026ccbbab1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac353ca5c1a54301b5ab530a48a7251a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16196ee874fe4a69ae027fdce5ad6bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deayalar/deeplearning_unitn/blob/main/DL_Project_wandb_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YOHCjjwPGWc",
        "outputId": "e4655849-8f2e-43f6-b37a-1c08758da97e"
      },
      "source": [
        "!wget https://market1501.s3-us-west-2.amazonaws.com/dataset.zip\n",
        "!unzip -q dataset.zip -d dataset"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-24 17:26:40--  https://market1501.s3-us-west-2.amazonaws.com/dataset.zip\n",
            "Resolving market1501.s3-us-west-2.amazonaws.com (market1501.s3-us-west-2.amazonaws.com)... 52.218.233.177\n",
            "Connecting to market1501.s3-us-west-2.amazonaws.com (market1501.s3-us-west-2.amazonaws.com)|52.218.233.177|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82925180 (79M) [application/zip]\n",
            "Saving to: â€˜dataset.zipâ€™\n",
            "\n",
            "dataset.zip         100%[===================>]  79.08M  41.8MB/s    in 1.9s    \n",
            "\n",
            "2021-06-24 17:26:42 (41.8 MB/s) - â€˜dataset.zipâ€™ saved [82925180/82925180]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_--0IpcYHBC_",
        "outputId": "e4308eb3-e016-4645-a4ae-1f5d1e76a478"
      },
      "source": [
        "!rm -rf /content/deeplearning_unitn\n",
        "!git clone https://github.com/deayalar/deeplearning_unitn.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deeplearning_unitn'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (239/239), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 239 (delta 131), reused 138 (delta 62), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (239/239), 10.71 MiB | 5.56 MiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUb-UELw5R_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db6d1e1-c5c0-422e-ead9-2bf04771125d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun 24 17:59:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P0    27W /  70W |   1912MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-GfOs_XIJGN"
      },
      "source": [
        "config = dict(\n",
        "    wandb = False,\n",
        "    device = \"auto\", # Select an specific device None to select automatically\n",
        "    train_root = \"/content/dataset/train\",\n",
        "    test_root = \"/content/dataset/test\", \n",
        "    queries_root = \"/content/dataset/queries\",\n",
        "    attributes_file = \"/content/dataset/annotations_train.csv\",\n",
        "    #train_root = \"/media/deayalar/Data/Documents/Unitn/Deep Learning/Assignment/dataset/train\",\n",
        "    #test_root = \"/media/deayalar/Data/Documents/Unitn/Deep Learning/Assignment/dataset/test\",\n",
        "    #queries_root = \"/media/deayalar/Data/Documents/Unitn/Deep Learning/Assignment/dataset/queries\",\n",
        "    #attributes_file = \"/media/deayalar/Data/Documents/Unitn/Deep Learning/Assignment/dataset/annotations_train.csv\",\n",
        "    dataset=\"Market1501\",\n",
        "    backbone = \"resnet18\",\n",
        "    split = dict(\n",
        "        full_training_size = 0.75,\n",
        "        train_size = 0.8\n",
        "    ),\n",
        "    compose = dict(\n",
        "        resize_h = 224,\n",
        "        resize_w = 224\n",
        "    ),\n",
        "    epochs=1,\n",
        "    training_batch_size=32,\n",
        "    validation_batch_size=32,\n",
        "    learning_rate=0.01,\n",
        "    weight_decay=0.000001, \n",
        "    momentum=0.9,\n",
        "    test_before_training=False,\n",
        "    test_after_epochs=10,\n",
        "    mAP_rank=15)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpj16wGSIgxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c17d1b3-5fd6-4659-c885-f1ecd68b16b1"
      },
      "source": [
        "%cd /content/deeplearning_unitn\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import cost_functions\n",
        "from evaluation import Evaluator\n",
        "from datasets.reid_dataset import Market1501\n",
        "#from cost_functions import OverallLossWrapper\n",
        "from utils.split_data import ValidationSplitter, TrainingSplitter\n",
        "from models.reid_model import FinetunedModel\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "if config[\"device\"] == \"auto\":\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "else:\n",
        "    device = config[\"device\"]\n",
        "print(device)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deeplearning_unitn\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE5e6DB4Igxs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "9f888fce-ed44-46ed-d154-3b261922dc6c"
      },
      "source": [
        "!pip install wandb -q\n",
        "import wandb\n",
        "if config[\"wandb\"]:\n",
        "  wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8MB 6.8MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174kB 22.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 10.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 26.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 8.6MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm98oBsFEHio"
      },
      "source": [
        "def model_pipeline(hyperparameters):\n",
        "    \"\"\"\n",
        "    This function corresponds to the basic pipeline of all tested models\n",
        "    0) Split data\n",
        "    1) Setup based on the configuration\n",
        "    2) Train the model\n",
        "    3) Test performance\n",
        "    \"\"\"\n",
        "    config = hyperparameters\n",
        "    if config[\"wandb\"]:\n",
        "      wandb.init(entity=\"dl_unitn\", project=\"dl_project\", config=hyperparameters)\n",
        "      config = wandb.config\n",
        "    print(config)\n",
        "    \n",
        "    train_set, val_set, val_queries = split_data(config)\n",
        "    \n",
        "    model, train_loader, val_loader, val_queries_loader, criterion, optimizer = setup(train_set, val_set, val_queries, config)\n",
        "    id_ground_truth_dict = build_ground_truth(val_set, val_queries)\n",
        "\n",
        "    print(\"Using \"+ config[\"backbone\"] + \" as backbone\")\n",
        "    if config[\"test_before_training\"]:\n",
        "      test(model, val_loader, val_queries_loader, id_ground_truth_dict, config)\n",
        "\n",
        "    train(model, train_loader, val_loader, criterion, optimizer, config)\n",
        "\n",
        "    test(model, val_loader, val_queries_loader, id_ground_truth_dict, config, save_model=True)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBoOUBtPIgxu"
      },
      "source": [
        "def build_ground_truth(val_set, val_queries):\n",
        "    values = []\n",
        "    for q in val_queries:\n",
        "        matches = []\n",
        "        for idx_v, v in enumerate(val_set):\n",
        "            if v.split(\"_\")[0] == q.split(\"_\")[0]:\n",
        "                matches.append(idx_v)\n",
        "        value = set(matches)\n",
        "        values.append(value)\n",
        "        \n",
        "    ground_truth_dict = dict(zip(list(range(0, len(val_queries))), values))\n",
        "    return ground_truth_dict\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0fYIjoLG2rv"
      },
      "source": [
        "def split_data(config):\n",
        "    \"\"\"Returns a list with the names of theimages in each set\"\"\"\n",
        "    splitter = ValidationSplitter(train_root=config[\"train_root\"], \n",
        "                                  test_root=config[\"test_root\"], \n",
        "                                  queries_root=config[\"queries_root\"])\n",
        "    train_set, val_set, val_queries = splitter.split(train_size=config[\"split\"][\"full_training_size\"],\n",
        "                                                     random_seed=42)\n",
        "    return train_set, val_set, val_queries\n",
        "\n",
        "def setup(train_set, val_set, val_queries, config):\n",
        "    #Create pytorch Datasets\n",
        "    train_composed = transforms.Compose([ transforms.Resize((config[\"compose\"][\"resize_h\"], \n",
        "                                                      config[\"compose\"][\"resize_w\"])),\n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                                std=[0.229, 0.224, 0.225]),\n",
        "                                          transforms.RandomErasing(p=0.6)])\n",
        "    \n",
        "    val_composed = transforms.Compose([transforms.Resize((config[\"compose\"][\"resize_h\"], \n",
        "                                                      config[\"compose\"][\"resize_w\"])),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                        std=[0.229, 0.224, 0.225])])\n",
        "    \n",
        "    train_dataset = Market1501(root_dir=config[\"train_root\"],\n",
        "                            attributes_file=config[\"attributes_file\"],\n",
        "                            images_list=train_set,\n",
        "                            transform=train_composed)\n",
        "                            \n",
        "    val_dataset = Market1501(root_dir=config[\"train_root\"],\n",
        "                         attributes_file=config[\"attributes_file\"],\n",
        "                         images_list=val_set,\n",
        "                         transform=val_composed)\n",
        "\n",
        "    val_queries_dataset = Market1501(root_dir=config[\"train_root\"],\n",
        "                         attributes_file=config[\"attributes_file\"],\n",
        "                         images_list=val_queries,\n",
        "                         transform=val_composed)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                               batch_size=config[\"training_batch_size\"], \n",
        "                                               shuffle=True, \n",
        "                                               num_workers=2)\n",
        "                                               \n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, \n",
        "                                             batch_size=config[\"validation_batch_size\"], \n",
        "                                             shuffle=False, \n",
        "                                             num_workers=2)\n",
        "\n",
        "    val_queries_loader = torch.utils.data.DataLoader(val_queries_dataset, \n",
        "                                             batch_size=config[\"validation_batch_size\"],\n",
        "                                             shuffle=False, \n",
        "                                             num_workers=2)\n",
        "\n",
        "    attr_len = len(train_dataset[0][2]) #Number of attributes in the csv: 27\n",
        "    print(f\"Number of attributes: {attr_len}\")\n",
        "    model = FinetunedModel(architecture=config[\"backbone\"] ,n_classes=attr_len).to(device)\n",
        "\n",
        "    #This is a combination of the attributes classification loss and the triplet loss for identification\n",
        "    criterion = OverallLossWrapper()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), \n",
        "                                lr=config[\"learning_rate\"], \n",
        "                                weight_decay=config[\"weight_decay\"], \n",
        "                                momentum=config[\"momentum\"])\n",
        "    \n",
        "    return model, train_loader, val_loader, val_queries_loader, criterion, optimizer"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0FUbfkUPZJb"
      },
      "source": [
        "def compute_centroids(model, loader):\n",
        "  model.eval()\n",
        "  print(\"Computing centroids\")\n",
        "  all_features = np.empty((0, model.feature_size))\n",
        "  ids = []\n",
        "  for batch_idx, (inputs, identity, attributes) in enumerate(tqdm(loader)):\n",
        "    inputs = inputs.to(device)\n",
        "    batch_features = model(inputs, get_features = True)\n",
        "    all_features = np.concatenate((all_features, batch_features.cpu().detach().numpy()), axis=0)\n",
        "    ids.extend(list(identity))\n",
        "\n",
        "  ids = np.array([int(i) for i in ids])\n",
        "  unique_ids = np.unique(ids)\n",
        "\n",
        "  centroids = []\n",
        "  for id in unique_ids:\n",
        "    id_features = all_features[ids == id]\n",
        "    centroid = np.mean(id_features, axis = 0)\n",
        "    centroids.append(centroid)\n",
        "  return centroids, unique_ids\n",
        "\n",
        "\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, config):\n",
        "    print(\"Training...\")\n",
        "    print(train_loader)\n",
        "    # tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
        "    if config[\"wandb\"]:\n",
        "         wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "    \n",
        "    # Run training and track with wandb\n",
        "    total_batches = len(train_loader) * config[\"epochs\"]\n",
        "    example_ct = 0  # number of seen examples\n",
        "    batch_ct = 0\n",
        "\n",
        "    centroids, unique_ids = compute_centroids(model, train_loader)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in tqdm(range(config[\"epochs\"])):\n",
        "        for batch_idx, (inputs, identity, attributes) in enumerate(train_loader):\n",
        "            loss = train_batch(inputs, identity, attributes, model, optimizer, criterion, centroids, unique_ids)\n",
        "\n",
        "            example_ct +=  len(inputs)\n",
        "            batch_ct += 1\n",
        "\n",
        "            if ((batch_ct + 1) % 50) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "            break\n",
        "\n",
        "        #centroids = compute_centroids(model, train_loader)\n",
        "\n",
        "\n",
        "def train_batch(inputs, identity, attributes, model, optimizer, criterion, centroids, unique_ids):\n",
        "    inputs = inputs.to(device)\n",
        "    attributes = attributes.to(device)\n",
        "    \n",
        "    # Forward pass\n",
        "    # TODO: This could be improved in the architecture to return both at the same time and improve the training time\n",
        "    output_attrs = model(inputs)\n",
        "    output_features = model(inputs, get_features=True)\n",
        "\n",
        "    # Filter the centroids and pass only the ones in the batch\n",
        "    centroids_batch = {}\n",
        "    for i in list(identity):\n",
        "      pos = np.flatnonzero(unique_ids==int(i))[0]\n",
        "      centroids_batch[i] = centroids[pos]\n",
        "\n",
        "    # Apply the loss\n",
        "    loss = criterion(output_attrs, attributes, output_features, identity, centroids_batch)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Step with optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdfG05psTqWb"
      },
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "    loss = float(loss)\n",
        "    if config[\"wandb\"]:\n",
        "        wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Epoch {epoch}: Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkgcTy5MIgx3"
      },
      "source": [
        "def get_features_from_loader(model, loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        all_features = torch.zeros(len(loader.dataset), model.feature_size)\n",
        "        for batch_idx, (inputs, ids, attr) in enumerate(tqdm(loader)):\n",
        "                inputs = inputs.to(device)\n",
        "                features = model(inputs, get_features=True)\n",
        "                for in_batch, f in enumerate(features):\n",
        "                    all_features[(batch_idx * loader.batch_size) + in_batch] = f\n",
        "        return all_features\n",
        "\n",
        "\n",
        "def test_mAP(model, gallery_loader, queries_loader, ground_truth_dict, config, save_model=False):\n",
        "    \"\"\"\n",
        "    This function returns the mAP performance of a given model \n",
        "    Params:\n",
        "    model: model to be evaluated\n",
        "    gallery: tensor that contains the feature representations of the target images in validation or test set\n",
        "    queries: tensor that contains feature representations of the queries\n",
        "    rank: top number of elements to retrieve\n",
        "\n",
        "    Returns:\n",
        "    mAP performance of the model\n",
        "    \"\"\"\n",
        "\n",
        "    # Run the model on some test examples\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        # Compute the features for queries and gallery\n",
        "        print(\"Computing gallery features...\")\n",
        "        gallery_features = get_features_from_loader(model, gallery_loader)\n",
        "        print(\"Computing query features...\")\n",
        "        query_features = get_features_from_loader(model, queries_loader)\n",
        "        \n",
        "        # Build the cosine similarity matrix between the all the queries and all the elements in gallery\n",
        "        print(\"Computing cosine similarities...\")\n",
        "        sims_matrix = torch.empty(query_features.size()[0], gallery_features.size()[0])\n",
        "        for idx, q in enumerate(query_features):\n",
        "            sims_matrix[idx] = F.cosine_similarity(q, gallery_features, dim=-1)\n",
        "        \n",
        "        print(\"Similarity matrix shape: \" + str(sims_matrix.size()))\n",
        "        sorted_index = torch.argsort(sims_matrix, dim=1, descending=True)\n",
        "        top_k = sorted_index.narrow_copy(dim=1, start=0, length=config[\"mAP_rank\"])\n",
        "\n",
        "        #Build the dictionary to compute the mAP\n",
        "        predictions_dict = {idx:  r for idx, r in enumerate(top_k.tolist())}\n",
        "        mAP = Evaluator.evaluate_map(predictions_dict, ground_truth_dict)\n",
        "        \n",
        "        print(f\"mAP: {mAP}\")\n",
        "        if config[\"wandb\"]:\n",
        "            wandb.log({\"mAP\": mAP})"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqwJwWFgIgx4"
      },
      "source": [
        "def get_attributes_from_loader(model, loader):\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = np.empty(shape=[0, 27], dtype=np.byte)\n",
        "    all_attrs = np.empty(shape=[0, 27], dtype=np.byte)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, ids, attr) in enumerate(tqdm(loader)):\n",
        "                inputs = inputs.to(device)\n",
        "                outputs = model(inputs, get_features=False)\n",
        "                #print(\"attr:\",attr)\n",
        "                predictions = torch.empty(attr.size()[1], attr.size()[0])\n",
        "                for attr_idx, output in enumerate(outputs):\n",
        "                    if output.size()[1] == 1: #If the output is binary\n",
        "                        pred = torch.round(torch.squeeze(output, 1))\n",
        "                    else: #Otherwise it is multiclass\n",
        "                        pred = torch.argmax(output, dim=1)\n",
        "                    predictions[attr_idx] = pred\n",
        "\n",
        "                predictions = torch.transpose(predictions, 0, 1).cpu().numpy()\n",
        "                attr = attr.cpu().numpy()\n",
        "\n",
        "                all_predictions = np.append(all_predictions, predictions, axis=0)\n",
        "                #print(\"all_predictions shape: \", all_predictions.shape)\n",
        "                all_attrs = np.append(all_attrs, attr, axis=0)\n",
        "                #print(\"all_attrs shape: \", all_attrs.shape)\n",
        "        return all_predictions, all_attrs\n",
        "\n",
        "def test_attributes(model, loader, config):\n",
        "    print(\"Computing attributes...\")\n",
        "    predictions, attr = get_attributes_from_loader(model, loader)\n",
        "    print(\"pred shape: \", predictions.shape)\n",
        "    print(\"attr shape: \", attr.shape)\n",
        "\n",
        "    accuracy_list = []\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    f1_score_list = []\n",
        "\n",
        "    for i in range(0, predictions.shape[1]):\n",
        "        y_true, y_pred = attr[:, i], predictions[:, i]\n",
        "        accuracy_list.append(accuracy_score(y_true, y_pred))\n",
        "        if i == 0: #If it is age\n",
        "            precision_list.append(precision_score(y_true, y_pred, average='macro'))\n",
        "            recall_list.append(recall_score(y_true, y_pred, average='macro'))\n",
        "            f1_score_list.append(f1_score(y_true, y_pred, average='macro'))\n",
        "        else:\n",
        "            precision_list.append(precision_score(y_true, y_pred))\n",
        "            recall_list.append(recall_score(y_true, y_pred))\n",
        "            f1_score_list.append(f1_score(y_true, y_pred))\n",
        "\n",
        "    average_acc = np.mean(accuracy_list)\n",
        "    average_precision = np.mean(precision_list)\n",
        "    average_recall = np.mean(recall_list)\n",
        "    average_f1score = np.mean(f1_score_list)\n",
        "\n",
        "    print(\"accuracy_list: \", accuracy_list)\n",
        "    print(\"precision_list: \", precision_list)\n",
        "    print(\"recall_list: \", recall_list)\n",
        "    print(\"f1_score_list: \", f1_score_list)\n",
        "\n",
        "    print(\"average_acc: \", average_acc)\n",
        "    print(\"average_precision: \", average_precision)\n",
        "    print(\"average_recall: \", average_recall)\n",
        "    print(\"average_f1score: \", average_f1score)\n",
        "\n",
        "    if config[\"wandb\"]:\n",
        "            wandb.log({\"accuracy_list\": accuracy_list})\n",
        "            wandb.log({\"precision_list\": precision_list})\n",
        "            wandb.log({\"recall_list\": recall_list})\n",
        "            wandb.log({\"f1_score_list\": f1_score_list})\n",
        "\n",
        "            wandb.log({\"average accuracy\": average_acc})\n",
        "            wandb.log({\"average precision\": average_precision})\n",
        "            wandb.log({\"average recall\": average_recall})\n",
        "            wandb.log({\"average f1\": average_f1score})"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN6pjSVOKTCt"
      },
      "source": [
        "def test(model, gallery_loader, queries_loader, ground_truth_dict, config, save_model=False):\n",
        "    print(\"Testing\")\n",
        "    model.eval()\n",
        "\n",
        "    test_mAP(model, gallery_loader, queries_loader, ground_truth_dict, config)\n",
        "    test_attributes(model, gallery_loader, config)\n",
        "\n",
        "    if save_model :\n",
        "      # Save the model in the exchangeable ONNX format\n",
        "      inputs, id, attr = next(iter(gallery_loader))\n",
        "      torch.onnx.export(model, inputs.to(device), \"model.onnx\", True)\n",
        "      if config[\"wandb\"]:\n",
        "        wandb.save(\"model.onnx\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqtuT4NEPu_a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662,
          "referenced_widgets": [
            "9344fdf74e6048389de94ef7e24097a0",
            "b665af91f02147fe8d2d799cf485b25f",
            "a7b49c77eaed45d7a6e69fae7b7ff184",
            "75feda6df9ce4c02bc48faa34d890dbd",
            "167cbc5246da470d81aea6a0429197a0",
            "d22b867029bd415785c9878b4287a90b",
            "d175e701167d4205b0b84a391f17ed9b",
            "eead41d247e34cda8a7735905bd8e445",
            "bc54899c2d384fec8a8443dcbe171a3c",
            "bb283e0e26cc4f0ba2b5eb98a9a4dd9e",
            "5f95520d91d949898da438a850ff0053",
            "06296f0d3eef4c8aa82bf3fcfcb3c7d9",
            "50c2d3a4fc2f4247a576149532264599",
            "9f1994c81ccf4f1085477026ccbbab1b",
            "ac353ca5c1a54301b5ab530a48a7251a",
            "16196ee874fe4a69ae027fdce5ad6bde"
          ]
        },
        "outputId": "45740fa8-89a6-4ddf-9bdd-f8c2a9939268"
      },
      "source": [
        "model = model_pipeline(config)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'wandb': False, 'device': 'auto', 'train_root': '/content/dataset/train', 'test_root': '/content/dataset/test', 'queries_root': '/content/dataset/queries', 'attributes_file': '/content/dataset/annotations_train.csv', 'dataset': 'Market1501', 'backbone': 'resnet18', 'split': {'full_training_size': 0.75, 'train_size': 0.8}, 'compose': {'resize_h': 224, 'resize_w': 224}, 'epochs': 1, 'training_batch_size': 32, 'validation_batch_size': 32, 'learning_rate': 0.01, 'weight_decay': 1e-06, 'momentum': 0.9, 'test_before_training': False, 'test_after_epochs': 10, 'mAP_rank': 15}\n",
            "Extract queries proportion: 0.11\n",
            "Identities in train set: 563\n",
            "Identities in validation set: 188\n",
            "Train set size: 9646\n",
            "Validation set size: 2975\n",
            "Number of validation queries: 368\n",
            "Number of attributes: 27\n",
            "Backbone feature size: 512\n",
            "Using resnet18 as backbone\n",
            "Training...\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7f4044044990>\n",
            "Computing centroids\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9344fdf74e6048389de94ef7e24097a0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=302.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc54899c2d384fec8a8443dcbe171a3c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "centroid torch.Size([512])\n",
            "input torch.Size([512])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-9807c214ebcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-daff8ed7dc8b>\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[0;34m(hyperparameters)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_queries_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_ground_truth_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_queries_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_ground_truth_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-04bd506cdfa9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, config)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mexample_ct\u001b[0m \u001b[0;34m+=\u001b[0m  \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-04bd506cdfa9>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(inputs, identity, attributes, model, optimizer, criterion, centroids, unique_ids)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Apply the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-74089c6ce942>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output_attrs, target_attrs, output_features, target_ids, centroids)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_attrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAttributesLossWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-74089c6ce942>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, targets, centroids_batch)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"centroid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mp_centroid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mdist_ap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mdist_an\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/distance.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mpairwise_distance\u001b[0;34m(x1, x2, p, eps, keepdim)\u001b[0m\n\u001b[1;32m   4204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairwise_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4206\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNEmFFbzjPuZ"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class OverallLossWrapper(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OverallLossWrapper, self).__init__()\n",
        "        self.id_loss = TripletLoss()\n",
        "        self.attr_loss = AttributesLossWrapper(0)\n",
        "\n",
        "    def forward(self, output_attrs, target_attrs, output_features, target_ids, centroids):\n",
        "        return self.id_loss(output_features, target_ids, centroids) + self.attr_loss(output_attrs, target_attrs)\n",
        "\n",
        "class AttributesLossWrapper(nn.Module):\n",
        "    def __init__(self, task_num):\n",
        "        super(AttributesLossWrapper, self).__init__()\n",
        "        self.task_num = task_num\n",
        "        # This is to learn the weights\n",
        "        #self.log_vars = nn.Parameter(torch.zeros((task_num)))\n",
        "\n",
        "    def forward(self, preds, attrs):\n",
        "\n",
        "        bce = nn.BCELoss()\n",
        "        crossEntropy = nn.CrossEntropyLoss()\n",
        "\n",
        "        loss_age = crossEntropy(preds[0], attrs[:,0])\n",
        "\n",
        "        binary_losses = 0\n",
        "        for idx in range(1, len(preds)):\n",
        "            binary_losses += bce(preds[idx], attrs[:, idx].unsqueeze(1).to(torch.float32))\n",
        "        return loss_age + binary_losses\n",
        "\n",
        "class TripletLoss(nn.Module):\n",
        "    \"\"\"Triplet loss with hard positive/negative mining.\n",
        "    Reference:\n",
        "    Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737.\n",
        "    Code imported from https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py.\n",
        "    Args:\n",
        "        margin (float): margin for triplet.\n",
        "    \"\"\"\n",
        "    def __init__(self, margin=0.3, mutual_flag = False):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.ranking_loss = nn.MarginRankingLoss(margin=margin)\n",
        "        self.mutual = mutual_flag\n",
        "\n",
        "    def forward(self, inputs, targets, centroids_batch):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs: feature matrix with shape (batch_size, feat_dim)\n",
        "            targets: ground truth labels with shape (num_classes)\n",
        "        \"\"\"\n",
        "        #print(centroids_batch)\n",
        "        #print(inputs.size())\n",
        "        str_targets = targets\n",
        "        targets = torch.Tensor(np.array([int(el) for el in targets]))\n",
        "        n = inputs.size(0)\n",
        "        # inputs = 1. * inputs / (torch.norm(inputs, 2, dim=-1, keepdim=True).expand_as(inputs) + 1e-12)\n",
        "        # Compute pairwise distance, replace by the official when merged\n",
        "\n",
        "        dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n)\n",
        "        dist = dist + dist.t()\n",
        "        dist.addmm_(1, -2, inputs, inputs.t())\n",
        "        dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n",
        "        # For each anchor, find the hardest positive and negative\n",
        "        mask = targets.expand(n, n).eq(targets.expand(n, n).t())\n",
        "        dist_ap, dist_an = [], []\n",
        "        p_centroid = []\n",
        "        pdist = nn.PairwiseDistance(p=2)\n",
        "        for i in range(n):\n",
        "            identity = str_targets[i]\n",
        "            print(\"centroid\", torch.from_numpy(centroids_batch[identity]).size())\n",
        "            print(\"input\", inputs[i].size())\n",
        "            p_centroid.append(pdist(inputs[i].cpu(), torch.from_numpy(centroids_batch[identity])))\n",
        "            dist_ap.append(dist[i][mask[i]].max().unsqueeze(0))\n",
        "            dist_an.append(dist[i][mask[i] == 0].min().unsqueeze(0))\n",
        "\n",
        "        dist_ap = torch.cat(dist_ap)\n",
        "        print(\"dist_ap\", dist_ap) #tensor of 32\n",
        "        print(dist_ap.size())\n",
        "        dist_an = torch.cat(dist_an)\n",
        "        # Compute ranking hinge loss\n",
        "        y = torch.ones_like(dist_an)\n",
        "        print(\"dist_an\", dist_an)\n",
        "        #print(y)\n",
        "        \n",
        "        #loss = self.ranking_loss(dist_an, dist_ap, y)\n",
        "        loss = self.ranking_loss(dist_an, torch.from_numpy(p_centroid), y)\n",
        "        if self.mutual:\n",
        "            return loss, dist\n",
        "        return loss"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaR4uXihvAn3",
        "outputId": "a51b8555-2f4b-41c6-afcb-5dabd44d60c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = torch.rand((32, 512))\n",
        "b = torch.rand((563, 512))\n",
        "\n",
        "dist = torch.cdist(a, b, p=2)\n",
        "\n",
        "negative = min (dist[0]) that is not the same id\n",
        "positive = max (dist[0]) that is the same id"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9.1077, 9.2527, 9.0059, 9.3490, 8.7549, 9.6457, 8.9666, 8.8905, 9.5018,\n",
              "        9.0124, 8.8881, 9.2553, 9.3594, 9.4746, 9.3200, 8.9975, 8.3942, 9.1485,\n",
              "        9.0249, 9.2816, 9.5297, 8.9594, 9.1508, 9.3641, 9.5101, 9.1946, 9.4404,\n",
              "        9.0432, 9.2503, 8.9881, 8.8168, 9.0690, 8.6096, 8.5686, 9.6819, 8.9559,\n",
              "        9.4789, 9.1671, 8.7684, 9.1548, 8.8964, 9.1857, 9.1477, 9.3215, 8.9102,\n",
              "        8.9241, 9.3771, 9.1190, 8.8493, 9.2508, 9.0688, 9.2244, 8.8989, 8.7872,\n",
              "        9.0755, 9.1341, 9.0156, 9.3387, 9.0489, 9.0347, 9.0635, 9.1890, 8.9042,\n",
              "        9.1982, 9.4264, 9.4672, 9.3545, 8.6607, 8.9085, 8.7460, 9.3902, 9.0370,\n",
              "        9.2789, 9.2119, 8.9597, 8.7021, 9.1411, 8.7086, 9.5176, 9.2895, 9.0412,\n",
              "        8.8813, 8.9221, 8.8463, 9.0196, 9.0545, 9.0770, 9.1636, 9.4220, 9.1278,\n",
              "        8.8784, 9.4415, 8.8359, 8.7734, 9.4948, 9.5703, 9.4541, 8.8690, 9.0236,\n",
              "        9.2140, 8.8267, 9.2566, 8.6593, 9.7477, 8.9224, 9.0083, 8.8235, 9.1405,\n",
              "        9.2027, 8.9853, 9.5817, 9.1122, 9.1633, 9.2006, 9.0537, 8.9092, 9.4705,\n",
              "        9.2729, 8.7723, 9.0941, 9.3181, 8.9221, 9.1448, 9.2631, 9.0066, 9.2352,\n",
              "        9.1750, 8.9255, 9.4531, 9.1555, 9.2136, 8.6380, 9.3782, 9.2355, 9.1852,\n",
              "        9.2777, 9.3337, 8.9607, 9.0038, 9.0788, 8.8695, 9.5488, 8.9475, 9.2462,\n",
              "        9.1990, 9.1134, 9.6319, 9.2045, 9.2518, 9.5541, 9.0920, 9.0355, 8.7142,\n",
              "        9.3011, 9.1374, 9.0575, 8.4800, 9.3177, 9.7257, 9.2817, 8.6814, 9.0120,\n",
              "        9.0680, 9.1130, 9.0329, 8.9587, 9.4773, 9.1856, 8.9557, 9.2651, 9.1714,\n",
              "        9.0394, 8.9027, 9.0923, 9.3181, 9.0965, 9.4524, 9.0509, 9.0420, 8.9959,\n",
              "        9.1555, 9.2407, 9.0485, 9.0256, 9.1991, 9.2320, 9.1404, 8.8289, 9.1285,\n",
              "        9.1750, 9.0448, 9.1801, 9.1588, 9.2025, 8.9770, 9.0049, 9.0287, 9.0593,\n",
              "        8.6514, 9.3017, 8.8046, 9.2385, 9.2251, 9.3277, 9.1539, 9.5642, 8.8330,\n",
              "        9.1278, 9.4866, 9.3512, 8.9672, 9.1711, 9.4154, 9.3053, 9.0624, 8.8971,\n",
              "        9.3011, 8.9622, 9.2247, 9.3146, 9.1564, 8.9155, 8.9822, 9.2745, 9.0816,\n",
              "        8.8043, 8.8412, 9.2132, 8.9054, 9.3335, 8.9218, 9.2273, 8.9855, 9.3713,\n",
              "        9.1290, 9.0267, 9.1083, 8.9605, 9.1859, 8.8875, 9.3584, 8.7068, 9.0748,\n",
              "        9.1611, 8.9620, 8.9098, 9.0191, 9.1448, 8.9371, 8.8963, 9.2562, 9.2690,\n",
              "        9.0314, 8.8431, 9.3164, 9.3979, 9.4931, 9.1632, 8.9497, 9.1938, 8.9068,\n",
              "        9.4316, 9.4298, 8.9523, 8.9159, 8.8794, 8.9672, 9.1192, 9.0848, 9.3909,\n",
              "        8.8226, 8.8995, 8.9856, 9.0232, 9.4483, 8.9851, 9.1530, 9.2457, 9.3517,\n",
              "        9.2311, 8.8893, 8.8273, 8.8719, 8.9383, 9.1532, 9.0241, 8.9894, 9.0728,\n",
              "        9.2511, 8.6843, 8.9462, 8.8603, 8.8484, 9.2592, 8.8876, 8.6874, 9.1537,\n",
              "        9.1122, 9.4680, 9.0294, 9.1633, 8.9225, 9.3240, 8.6573, 9.0558, 9.2198,\n",
              "        8.9458, 9.3785, 9.0959, 9.0825, 9.0766, 9.2826, 9.4038, 9.1855, 8.9992,\n",
              "        9.0041, 9.1155, 8.6964, 9.2642, 9.1985, 8.7388, 9.2379, 9.1195, 9.0370,\n",
              "        9.0287, 8.7009, 9.2457, 9.3323, 9.3673, 9.1626, 9.0021, 9.2787, 8.9062,\n",
              "        9.1072, 9.5959, 9.2051, 9.0356, 8.6531, 9.2340, 8.8305, 8.8031, 9.3376,\n",
              "        8.8205, 9.4443, 9.0982, 9.4118, 8.9933, 9.3886, 9.2582, 9.2899, 9.2403,\n",
              "        9.5029, 9.1826, 9.3512, 8.8972, 9.1138, 8.9298, 9.3405, 8.9702, 9.1940,\n",
              "        9.1973, 8.9322, 9.0147, 9.2810, 9.2250, 9.6023, 9.5591, 9.1451, 8.7848,\n",
              "        9.2122, 9.8948, 8.8751, 9.1735, 9.0036, 8.8568, 9.1078, 8.9998, 8.7338,\n",
              "        9.1509, 9.4570, 9.6163, 9.1949, 9.0117, 9.3031, 9.3615, 9.1418, 9.2060,\n",
              "        9.0012, 8.9744, 9.1398, 9.2580, 9.1687, 8.9249, 9.0341, 9.0851, 9.4385,\n",
              "        9.0251, 9.0467, 9.2992, 9.0012, 9.0482, 9.1908, 8.7454, 8.9925, 9.3232,\n",
              "        8.7506, 9.0750, 8.7181, 9.1098, 9.0107, 9.2858, 9.4642, 9.3707, 9.1030,\n",
              "        8.6641, 9.1667, 8.9685, 9.3291, 9.0333, 8.9190, 9.1121, 8.7361, 9.1056,\n",
              "        9.0415, 9.0241, 9.1523, 9.2089, 9.3091, 9.2542, 9.2573, 9.2378, 9.4306,\n",
              "        8.9620, 9.2697, 9.1677, 9.0625, 8.9239, 9.3371, 9.1458, 8.9395, 8.9637,\n",
              "        9.2595, 8.7872, 8.9383, 9.0846, 9.1829, 8.9852, 9.3262, 8.6551, 8.6555,\n",
              "        9.4028, 9.1639, 9.0686, 8.7229, 8.9882, 9.0469, 9.2021, 9.0036, 8.9216,\n",
              "        9.2754, 8.8540, 9.2472, 9.2178, 9.0478, 9.0645, 8.9676, 9.5164, 9.1721,\n",
              "        9.5089, 8.8268, 9.2493, 9.1189, 9.3839, 8.6704, 8.9692, 9.2388, 8.8359,\n",
              "        9.1146, 8.6761, 8.9916, 9.1450, 9.1597, 9.1275, 9.3689, 9.1775, 9.2118,\n",
              "        9.4007, 9.0501, 8.8162, 9.3531, 9.1401, 9.5674, 9.2450, 9.0129, 9.3306,\n",
              "        9.3169, 8.9040, 8.7146, 9.2516, 8.8389, 9.4061, 8.8425, 9.0428, 9.0147,\n",
              "        9.3131, 9.1555, 9.2176, 8.9021, 8.7710, 8.9881, 9.1188, 9.2494, 8.7994,\n",
              "        8.8329, 9.7173, 9.0048, 9.1138, 9.2133, 9.2230, 8.8421, 9.2974, 9.2309,\n",
              "        9.0522, 9.1713, 9.3064, 8.9523, 9.2140, 9.0915, 9.1844, 8.9207, 8.9780,\n",
              "        8.8852, 8.9544, 9.1235, 9.1584, 9.3158, 9.1307, 9.1377, 9.3197, 9.3972,\n",
              "        9.5152, 9.4043, 9.0425, 9.3307, 8.9853, 9.1247, 8.8389, 9.0871, 9.1822,\n",
              "        8.8874, 9.3139, 9.0495, 8.8449, 8.8406, 9.0195, 8.9479, 9.0290, 8.8729,\n",
              "        9.5122, 8.9134, 9.3307, 9.3868, 9.2268])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    }
  ]
}